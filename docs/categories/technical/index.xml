<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Technical on AI Meanderings</title>
    <link>/categories/technical/</link>
    <description>Recent content in Technical on AI Meanderings</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 01 Nov 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="/categories/technical/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ML Foundations: Understanding the Math Behind Backpropagation</title>
      <link>/posts/understanding-the-math-behind-backpropagation/</link>
      <pubDate>Fri, 01 Nov 2024 00:00:00 +0000</pubDate>
      <guid>/posts/understanding-the-math-behind-backpropagation/</guid>
      <description>&lt;p&gt;The past decade has marked a heyday for neural networks, driving innovations from deep learning advancements to the rise of transformer models that power tools like ChatGPT, Claude, and other large language models. Recently, Geoffrey Hinton was even &lt;a href=&#34;https://www.utoronto.ca/news/geoffrey-hinton-wins-nobel-prize#:~:text=Geoffrey%20Hinton%2C%20a%20University%20Professor,2024%20Nobel%20Prize%20in%20Physics&#34;&gt;awarded the Nobel Prize in Physics&lt;/a&gt; for his pioneering contributions to neural networks - a testament to the profound impact of these models on both AI and society.&lt;/p&gt;&#xA;&lt;p&gt;While a variety of powerful libraries, such as PyTorch, TensorFlow, and JAX, have simplified the process of training and deploying neural networks, developing an understanding of their underlying principles remains invaluable. In this post, I’ll guide you through the mathematical underpinnings of backpropagation, a key algorithm for training neural networks, and demonstrate how to implement it from scratch using Python with NumPy. We’ll apply this knowledge to train a simple fully connected neural network for classifying images in the &lt;a href=&#34;https://www.kaggle.com/datasets/hojjatk/mnist-dataset&#34;&gt;MNIST dataset&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
